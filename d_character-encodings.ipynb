{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94b87c",
   "metadata": {
    "papermill": {
     "duration": 0.006959,
     "end_time": "2023-04-20T18:08:46.775285",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.768326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook, we're going to be working with different character encodings. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c443a8",
   "metadata": {
    "papermill": {
     "duration": 0.005233,
     "end_time": "2023-04-20T18:08:46.786272",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.781039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get our environment set up\n",
    "\n",
    "The first thing we'll need to do is load in the libraries we'll be using. Not our dataset, though: we'll get to it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479a9b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.800758Z",
     "iopub.status.busy": "2023-04-20T18:08:46.800333Z",
     "iopub.status.idle": "2023-04-20T18:08:46.811655Z",
     "shell.execute_reply": "2023-04-20T18:08:46.810305Z"
    },
    "papermill": {
     "duration": 0.022408,
     "end_time": "2023-04-20T18:08:46.814372",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.791964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpful character encoding module\n",
    "import charset_normalizer\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b67f08",
   "metadata": {
    "papermill": {
     "duration": 0.005257,
     "end_time": "2023-04-20T18:08:46.825217",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.819960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What are encodings?\n",
    "\n",
    "**Character encodings** are specific sets of rules for mapping from raw binary byte strings (that look like this: 0110100001101001) to characters that make up human-readable text (like \"hi\"). There are many different encodings, and if you tried to read in text with a different encoding than the one it was originally written in, you ended up with scrambled text called \"mojibake\" (said like mo-gee-bah-kay). Here's an example of mojibake:\n",
    "\n",
    "æ–‡å—åŒ–ã??\n",
    "\n",
    "You might also end up with a \"unknown\" characters. There are what gets printed when there's no mapping between a particular byte and a character in the encoding you're using to read your byte string in and they look like this:\n",
    "\n",
    "����������\n",
    "\n",
    "Character encoding mismatches are less common today than they used to be, but it's definitely still a problem. There are lots of different character encodings, but the main one you need to know is UTF-8.\n",
    "\n",
    "> UTF-8 is **the** standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. It's when things aren't in UTF-8 that you run into trouble.\n",
    "\n",
    "It was pretty hard to deal with encodings in Python 2, but thankfully in Python 3 it's a lot simpler. (Kaggle Notebooks only use Python 3.) There are two main data types you'll encounter when working with text in Python 3. One is is the string, which is what text is by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5885b7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.838394Z",
     "iopub.status.busy": "2023-04-20T18:08:46.837963Z",
     "iopub.status.idle": "2023-04-20T18:08:46.847093Z",
     "shell.execute_reply": "2023-04-20T18:08:46.845492Z"
    },
    "papermill": {
     "duration": 0.019459,
     "end_time": "2023-04-20T18:08:46.850232",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.830773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with a string\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# check to see what datatype it is\n",
    "type(before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cdfc3f",
   "metadata": {
    "papermill": {
     "duration": 0.005407,
     "end_time": "2023-04-20T18:08:46.861651",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.856244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The other data is the [bytes](https://docs.python.org/3.1/library/functions.html#bytes) data type, which is a sequence of integers. You can convert a string into bytes by specifying which encoding it's in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e403f864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.875110Z",
     "iopub.status.busy": "2023-04-20T18:08:46.874680Z",
     "iopub.status.idle": "2023-04-20T18:08:46.883351Z",
     "shell.execute_reply": "2023-04-20T18:08:46.881773Z"
    },
    "papermill": {
     "duration": 0.019167,
     "end_time": "2023-04-20T18:08:46.886501",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.867334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "# check the type\n",
    "type(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29881f",
   "metadata": {
    "papermill": {
     "duration": 0.005362,
     "end_time": "2023-04-20T18:08:46.897757",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.892395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you look at a bytes object, you'll see that it has a b in front of it, and then maybe some text after. That's because bytes are printed out as if they were characters encoded in ASCII. (ASCII is an older character encoding that doesn't really work for writing any language other than English.) Here you can see that our euro symbol  has been replaced with some mojibake that looks like \"\\xe2\\x82\\xac\" when it's printed as if it were an ASCII string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb23997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.911342Z",
     "iopub.status.busy": "2023-04-20T18:08:46.910914Z",
     "iopub.status.idle": "2023-04-20T18:08:46.918284Z",
     "shell.execute_reply": "2023-04-20T18:08:46.916905Z"
    },
    "papermill": {
     "duration": 0.017103,
     "end_time": "2023-04-20T18:08:46.920534",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.903431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is the euro symbol: \\xe2\\x82\\xac'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the bytes look like\n",
    "after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeeffaf",
   "metadata": {
    "papermill": {
     "duration": 0.005396,
     "end_time": "2023-04-20T18:08:46.931640",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.926244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When we convert our bytes back to a string with the correct encoding, we can see that our text is all there correctly, which is great! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301662e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.945299Z",
     "iopub.status.busy": "2023-04-20T18:08:46.944783Z",
     "iopub.status.idle": "2023-04-20T18:08:46.951529Z",
     "shell.execute_reply": "2023-04-20T18:08:46.949827Z"
    },
    "papermill": {
     "duration": 0.016874,
     "end_time": "2023-04-20T18:08:46.954159",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.937285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "# convert it back to utf-8\n",
    "print(after.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc67252",
   "metadata": {
    "papermill": {
     "duration": 0.005452,
     "end_time": "2023-04-20T18:08:46.966671",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.961219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "However, when we try to use a different encoding to map our bytes into a string, we get an error. This is because the encoding we're trying to use doesn't know what to do with the bytes we're trying to pass it. You need to tell Python the encoding that the byte string is actually supposed to be in.\n",
    "\n",
    "> You can think of different encodings as different ways of recording music. You can record the same music on a CD, cassette tape or 8-track. While the music may sound more-or-less the same, you need to use the right equipment to play the music from each recording format. The correct decoder is like a cassette player or a CD player. If you try to play a cassette in a CD player, it just won't work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a13f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:46.980909Z",
     "iopub.status.busy": "2023-04-20T18:08:46.980411Z",
     "iopub.status.idle": "2023-04-20T18:08:47.050467Z",
     "shell.execute_reply": "2023-04-20T18:08:47.048923Z"
    },
    "papermill": {
     "duration": 0.080729,
     "end_time": "2023-04-20T18:08:47.053522",
     "exception": false,
     "start_time": "2023-04-20T18:08:46.972793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\d_character-encodings.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# try to decode our bytes with the ascii encoding\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(after\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# try to decode our bytes with the ascii encoding\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7727b56",
   "metadata": {
    "papermill": {
     "duration": 0.005807,
     "end_time": "2023-04-20T18:08:47.065479",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.059672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also run into trouble if we try to use the wrong encoding to map from a string to bytes. Like I said earlier, strings are UTF-8 by default in Python 3, so if we try to treat them like they were in another encoding we'll create problems. \n",
    "\n",
    "For example, if we try to convert a string to bytes for ASCII using `encode()`, we can ask for the bytes to be what they would be if the text was in ASCII. Since our text isn't in ASCII, though, there will be some characters it can't handle. We can automatically replace the characters that ASCII can't handle. If we do that, however, any characters not in ASCII will just be replaced with the unknown character. Then, when we convert the bytes back to a string, the character will be replaced with the unknown character. The dangerous part about this is that there's not way to tell which character it *should* have been. That means we may have just made our data unusable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31214e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:47.079753Z",
     "iopub.status.busy": "2023-04-20T18:08:47.079296Z",
     "iopub.status.idle": "2023-04-20T18:08:47.086242Z",
     "shell.execute_reply": "2023-04-20T18:08:47.084867Z"
    },
    "papermill": {
     "duration": 0.017281,
     "end_time": "2023-04-20T18:08:47.088663",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.071382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: ?\n"
     ]
    }
   ],
   "source": [
    "# start with a string\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# convert it back to utf-8\n",
    "print(after.decode(\"ascii\"))\n",
    "\n",
    "# We've lost the original underlying byte string! It's been \n",
    "# replaced with the underlying byte string for the unknown character :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1855c",
   "metadata": {
    "papermill": {
     "duration": 0.006579,
     "end_time": "2023-04-20T18:08:47.101443",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.094864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is bad and we want to avoid doing it! It's far better to convert all our text to UTF-8 as soon as we can and keep it in that encoding. The best time to convert non UTF-8 input into UTF-8  is when you read in files, which we'll talk about next.\n",
    "\n",
    "# Reading in files with encoding problems\n",
    "\n",
    "Most files you'll encounter will probably be encoded with UTF-8. This is what Python expects by default, so most of the time you won't run into problems. However, sometimes you'll get an error like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a7a0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:47.116055Z",
     "iopub.status.busy": "2023-04-20T18:08:47.115536Z",
     "iopub.status.idle": "2023-04-20T18:08:47.208144Z",
     "shell.execute_reply": "2023-04-20T18:08:47.206418Z"
    },
    "papermill": {
     "duration": 0.103525,
     "end_time": "2023-04-20T18:08:47.211179",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.107654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAMADHAN\\AppData\\Local\\Temp\\ipykernel_7812\\108388597.py:2: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  kickstarter_2016 = pd.read_csv(\"Data_Source\\ks-projects-201801-utf8.csv\")\n"
     ]
    }
   ],
   "source": [
    "# try to read in a file not in UTF-8\n",
    "kickstarter_2016 = pd.read_csv(\"Data_Source\\ks-projects-201801-utf8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1000023410</td>\n",
       "      <td>Support Solar Roasted Coffee &amp; Green Energy!  ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-12-21 18:30:44</td>\n",
       "      <td>1000</td>\n",
       "      <td>2014-12-01 18:30:44</td>\n",
       "      <td>1205</td>\n",
       "      <td>successful</td>\n",
       "      <td>16</td>\n",
       "      <td>US</td>\n",
       "      <td>1205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1000030581</td>\n",
       "      <td>Chaser Strips. Our Strips make Shots their B*tch!</td>\n",
       "      <td>Drinks</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-03-17 19:05:12</td>\n",
       "      <td>25000</td>\n",
       "      <td>2016-02-01 20:05:12</td>\n",
       "      <td>453</td>\n",
       "      <td>failed</td>\n",
       "      <td>40</td>\n",
       "      <td>US</td>\n",
       "      <td>453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1000034518</td>\n",
       "      <td>SPIN - Premium Retractable In-Ear Headphones w...</td>\n",
       "      <td>Product Design</td>\n",
       "      <td>Design</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-05-29 18:14:43</td>\n",
       "      <td>125000</td>\n",
       "      <td>2014-04-24 18:14:43</td>\n",
       "      <td>8233</td>\n",
       "      <td>canceled</td>\n",
       "      <td>58</td>\n",
       "      <td>US</td>\n",
       "      <td>8233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>100004195</td>\n",
       "      <td>STUDIO IN THE SKY - A Documentary Feature Film...</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-08-10 21:55:48</td>\n",
       "      <td>65000</td>\n",
       "      <td>2014-07-11 21:55:48</td>\n",
       "      <td>6240.57</td>\n",
       "      <td>canceled</td>\n",
       "      <td>43</td>\n",
       "      <td>US</td>\n",
       "      <td>6240.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>100004721</td>\n",
       "      <td>Of Jesus and Madmen</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>CAD</td>\n",
       "      <td>2013-10-09 18:19:37</td>\n",
       "      <td>2500</td>\n",
       "      <td>2013-09-09 18:19:37</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>100005484</td>\n",
       "      <td>Lisa Lim New CD!</td>\n",
       "      <td>Indie Rock</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-04-08 06:42:58</td>\n",
       "      <td>12500</td>\n",
       "      <td>2013-03-09 06:42:58</td>\n",
       "      <td>12700</td>\n",
       "      <td>successful</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>12700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1000055792</td>\n",
       "      <td>The Cottage Market</td>\n",
       "      <td>Crafts</td>\n",
       "      <td>Crafts</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-10-02 17:11:50</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014-09-02 17:11:50</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1000056157</td>\n",
       "      <td>G-Spot Place for Gamers to connect with eachot...</td>\n",
       "      <td>Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-03-25 22:01:12</td>\n",
       "      <td>200000</td>\n",
       "      <td>2016-02-09 23:01:12</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1000064368</td>\n",
       "      <td>Survival Rings</td>\n",
       "      <td>Design</td>\n",
       "      <td>Design</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-02-28 02:10:53</td>\n",
       "      <td>2500</td>\n",
       "      <td>2015-01-29 02:10:53</td>\n",
       "      <td>664</td>\n",
       "      <td>failed</td>\n",
       "      <td>11</td>\n",
       "      <td>US</td>\n",
       "      <td>664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1000064918</td>\n",
       "      <td>The Beard</td>\n",
       "      <td>Comic Books</td>\n",
       "      <td>Comics</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-11-08 22:27:52</td>\n",
       "      <td>1500</td>\n",
       "      <td>2014-10-09 22:27:52</td>\n",
       "      <td>395</td>\n",
       "      <td>failed</td>\n",
       "      <td>16</td>\n",
       "      <td>US</td>\n",
       "      <td>395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         ID                                               name   \\\n",
       "5            5  1000023410  Support Solar Roasted Coffee & Green Energy!  ...   \n",
       "6            6  1000030581  Chaser Strips. Our Strips make Shots their B*tch!   \n",
       "7            7  1000034518  SPIN - Premium Retractable In-Ear Headphones w...   \n",
       "8            8   100004195  STUDIO IN THE SKY - A Documentary Feature Film...   \n",
       "9            9   100004721                                Of Jesus and Madmen   \n",
       "10          10   100005484                                   Lisa Lim New CD!   \n",
       "11          11  1000055792                                 The Cottage Market   \n",
       "12          12  1000056157  G-Spot Place for Gamers to connect with eachot...   \n",
       "13          13  1000064368                                     Survival Rings   \n",
       "14          14  1000064918                                          The Beard   \n",
       "\n",
       "         category  main_category  currency             deadline    goal   \\\n",
       "5             Food           Food       USD  2014-12-21 18:30:44    1000   \n",
       "6           Drinks           Food       USD  2016-03-17 19:05:12   25000   \n",
       "7   Product Design         Design       USD  2014-05-29 18:14:43  125000   \n",
       "8      Documentary   Film & Video       USD  2014-08-10 21:55:48   65000   \n",
       "9       Nonfiction     Publishing       CAD  2013-10-09 18:19:37    2500   \n",
       "10      Indie Rock          Music       USD  2013-04-08 06:42:58   12500   \n",
       "11          Crafts         Crafts       USD  2014-10-02 17:11:50    5000   \n",
       "12           Games          Games       USD  2016-03-25 22:01:12  200000   \n",
       "13          Design         Design       USD  2015-02-28 02:10:53    2500   \n",
       "14     Comic Books         Comics       USD  2014-11-08 22:27:52    1500   \n",
       "\n",
       "              launched  pledged       state  backers  country  usd pledged   \\\n",
       "5   2014-12-01 18:30:44     1205  successful       16       US         1205   \n",
       "6   2016-02-01 20:05:12      453      failed       40       US          453   \n",
       "7   2014-04-24 18:14:43     8233    canceled       58       US         8233   \n",
       "8   2014-07-11 21:55:48  6240.57    canceled       43       US      6240.57   \n",
       "9   2013-09-09 18:19:37        0      failed        0       CA            0   \n",
       "10  2013-03-09 06:42:58    12700  successful      100       US        12700   \n",
       "11  2014-09-02 17:11:50        0      failed        0       US            0   \n",
       "12  2016-02-09 23:01:12        0      failed        0       US            0   \n",
       "13  2015-01-29 02:10:53      664      failed       11       US          664   \n",
       "14  2014-10-09 22:27:52      395      failed       16       US          395   \n",
       "\n",
       "   Unnamed: 13 Unnamed: 14 Unnamed: 15  Unnamed: 16  \n",
       "5          NaN         NaN         NaN          NaN  \n",
       "6          NaN         NaN         NaN          NaN  \n",
       "7          NaN         NaN         NaN          NaN  \n",
       "8          NaN         NaN         NaN          NaN  \n",
       "9          NaN         NaN         NaN          NaN  \n",
       "10         NaN         NaN         NaN          NaN  \n",
       "11         NaN         NaN         NaN          NaN  \n",
       "12         NaN         NaN         NaN          NaN  \n",
       "13         NaN         NaN         NaN          NaN  \n",
       "14         NaN         NaN         NaN          NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kickstarter_2016[5:15]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89b505e7",
   "metadata": {
    "papermill": {
     "duration": 0.006747,
     "end_time": "2023-04-20T18:08:47.224716",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.217969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that we get the same `UnicodeDecodeError` we got when we tried to decode UTF-8 bytes as if they were ASCII! This tells us that this file isn't actually UTF-8. We don't know what encoding it actually *is* though. One way to figure it out is to try and test a bunch of different character encodings and see if any of them work. A better way, though, is to use the charset_normalizer module to try and automatically guess what the right encoding is. It's not 100% guaranteed to be right, but it's usually faster than just trying to guess.\n",
    "\n",
    "I'm going to just look at the first ten thousand bytes of this file. This is usually enough for a good guess about what the encoding is and is much faster than trying to look at the whole file. (Especially with a  large file this can be very slow.) Another reason to just look at the first part of the file is that  we can see by looking at the error message that the first problem is the 11th character. So we probably only need to look at the first little bit of the file to figure out what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dedccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:47.241937Z",
     "iopub.status.busy": "2023-04-20T18:08:47.240707Z",
     "iopub.status.idle": "2023-04-20T18:08:47.310581Z",
     "shell.execute_reply": "2023-04-20T18:08:47.309265Z"
    },
    "papermill": {
     "duration": 0.081605,
     "end_time": "2023-04-20T18:08:47.313109",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.231504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'language': 'Spanish', 'confidence': 0.991}\n"
     ]
    }
   ],
   "source": [
    "# look at the first ten thousand bytes to guess the character encoding\n",
    "with open(\"Data_Source\\ks-projects-201801-utf8.csv\", 'rb') as rawdata:\n",
    "    result = charset_normalizer.detect(rawdata.read(10000))\n",
    "\n",
    "# check what the character encoding might be\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5f57b15",
   "metadata": {
    "papermill": {
     "duration": 0.006239,
     "end_time": "2023-04-20T18:08:47.325785",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.319546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So charset_normalizer is 73%  confidence that the right encoding is \"Windows-1252\". Let's see if that's correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1e0022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:47.341834Z",
     "iopub.status.busy": "2023-04-20T18:08:47.340766Z",
     "iopub.status.idle": "2023-04-20T18:08:50.004858Z",
     "shell.execute_reply": "2023-04-20T18:08:50.002951Z"
    },
    "papermill": {
     "duration": 2.674787,
     "end_time": "2023-04-20T18:08:50.007684",
     "exception": false,
     "start_time": "2023-04-20T18:08:47.332897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 60806: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\d_character-encodings.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# read in the file with the encoding detected by charset_normalizer\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m kickstarter_2016 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mData_Source\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mks-projects-201801-utf8.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mWindows-1252\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# look at the first few lines\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/Code/Kaggle%20%28Data%20Mining%29/Data%20Cleaning/d_character-encodings.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m kickstarter_2016\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh:\\Code\\Kaggle (Data Mining)\\Data Cleaning\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 60806: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# read in the file with the encoding detected by charset_normalizer\n",
    "kickstarter_2016 = pd.read_csv(\n",
    "    \"Data_Source\\ks-projects-201801-utf8.csv\", encoding='Windows-1252')\n",
    "\n",
    "# look at the first few lines\n",
    "kickstarter_2016.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5c5c650",
   "metadata": {
    "papermill": {
     "duration": 0.006959,
     "end_time": "2023-04-20T18:08:50.022390",
     "exception": false,
     "start_time": "2023-04-20T18:08:50.015431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yep, looks like charset_normalizer was right! The file reads in with no problem (although we do get a warning about datatypes) and when we look at the first few rows it seems to be fine. \n",
    "\n",
    "> **What if the encoding charset_normalizer guesses isn't right?** Since charset_normalizer is basically just a fancy guesser, sometimes it will guess the wrong encoding. One thing you can try is looking at more or less of the file and seeing if you get a different result and then try that.\n",
    "\n",
    "# Saving your files with UTF-8 encoding\n",
    "\n",
    "Finally, once you've gone through all the trouble of getting your file into UTF-8, you'll probably want to keep it that way. The easiest way to do that is to save your files with UTF-8 encoding. The good news is, since UTF-8 is the standard encoding in Python, when you save a file it will be saved as UTF-8 by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859c76ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:08:50.040060Z",
     "iopub.status.busy": "2023-04-20T18:08:50.038631Z",
     "iopub.status.idle": "2023-04-20T18:08:52.278482Z",
     "shell.execute_reply": "2023-04-20T18:08:52.276872Z"
    },
    "papermill": {
     "duration": 2.252257,
     "end_time": "2023-04-20T18:08:52.281822",
     "exception": false,
     "start_time": "2023-04-20T18:08:50.029565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save our file (will be saved as UTF-8 by default!)\n",
    "kickstarter_2016.to_csv(\"ks-projects-201801-utf8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8412a",
   "metadata": {
    "papermill": {
     "duration": 0.007175,
     "end_time": "2023-04-20T18:08:52.296978",
     "exception": false,
     "start_time": "2023-04-20T18:08:52.289803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pretty easy, huh? :)\n",
    "\n",
    "# Your turn! \n",
    "\n",
    "[**Deepen your understanding**](https://www.kaggle.com/kernels/fork/10824401) with a dataset of fatal police shootings in the US. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67885e95",
   "metadata": {
    "papermill": {
     "duration": 0.00709,
     "end_time": "2023-04-20T18:08:52.311896",
     "exception": false,
     "start_time": "2023-04-20T18:08:52.304806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.519221,
   "end_time": "2023-04-20T18:08:53.345453",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-20T18:08:35.826232",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
